{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project our goal is to build a movie recommendation system using collaborative filtering. Collaborative filtering is a learning technique used to make predictions (filtering) about the interests of a user by collecting preferences of taste information from many other users (collaboration). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.\n",
    "\n",
    "For this task, the [Movielens dataset](https://grouplens.org/datasets/movielens/) was used. It contains over 1 million anonymous ratings applied to 3883 movies by 6040 users.\n",
    "\n",
    "The Apache Spark framework (and its Machine Learning library) was used to process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some functionalities of the Spark SQL component will be used, we need to initialize a `SparkSession` object.\n",
    "\n",
    "The `SparkContext` object (required for other basic functionalities) is automatically created by PySpark and it is defined in the `sc` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the (singleton) SparkSession object.\n",
    "ss = SparkSession.builder.appName(\"Movie Recommendation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset is composed of three text files:\n",
    "\n",
    "- `users.dat`: contains information about the genre, age, occupation and zipcode of each user.\n",
    "- `movies.dat`: contains information about the title, year and genres of each movie.\n",
    "- `ratings.dat`: contains the ratings that users gave to the movies they watched.\n",
    "\n",
    "They can be opened as plain text RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::F::1::10::48067',\n",
       " '2::M::56::16::70072',\n",
       " '3::M::25::15::55117',\n",
       " '4::M::45::7::02460',\n",
       " '5::M::25::20::55455']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the users data from a text file.\n",
    "# The records are read as strings.\n",
    "usersRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"users.dat\"))\n",
    "usersRdd0.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1::Toy Story (1995)::Animation|Children's|Comedy\",\n",
       " \"2::Jumanji (1995)::Adventure|Children's|Fantasy\",\n",
       " '3::Grumpier Old Men (1995)::Comedy|Romance',\n",
       " '4::Waiting to Exhale (1995)::Comedy|Drama',\n",
       " '5::Father of the Bride Part II (1995)::Comedy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the movies data from a text file.\n",
    "# The records are read as strings.\n",
    "moviesRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"movies.dat\"))\n",
    "moviesRdd0.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275',\n",
       " '1::2355::5::978824291']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the ratings data from a text file.\n",
    "# The records are read as strings.\n",
    "ratingsRdd0 = sc.textFile(os.path.join(\"ml-1m\", \"ratings.dat\"))\n",
    "ratingsRdd0.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plain text RDDs must be converted to structured dataframes so we can use SQL queries and other high level operations to manipulate them. This is done for each RDD separately as each dataset has its own schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import Row\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MovieLens dataset's documentation, each user record is composed of 5 fields:\n",
    "\n",
    "- userID: User's unique identification.\n",
    "- gender: User's gender (\"F\" for females, \"M\" for males).\n",
    "- age: User's age range encoded as a number (see below).\n",
    "- occupation: User's occupation encoded as a number (see below).\n",
    "- zipcode: User's zipcode.\n",
    "\n",
    "We usually need to encode categorical features as numbers (or sets of binary features) in order to employ them as features for predictive models. Here, the `age` and `occupation` field values are already encoded; however, in a preliminary analysis it might be useful to know their actual values for the sake of interpretation. So the default encoding is undone and the codes are translated to the actual values they represent. Later, when needed, we may encode them again using Spark's `StringIndexer` class.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each user is split, the field values are computed, and the result is put into a structured `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map age codes to their true meanings.\n",
    "agesDict = {\n",
    "    \"1\": \"Under 18\",\n",
    "    \"18\": \"18-24\",\n",
    "    \"25\": \"25-34\",\n",
    "    \"35\": \"35-44\",\n",
    "    \"45\": \"45-49\",\n",
    "    \"50\": \"50-55\",\n",
    "    \"56\": \"Over 56\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map occupation codes to their true meanings.\n",
    "occupationsDict = {\n",
    "    \"0\": \"other or unspecified\",\n",
    "    \"1\": \"academic/educator\",\n",
    "    \"2\": \"artist\",\n",
    "    \"3\": \"clerical/admin\",\n",
    "    \"4\": \"college/grad student\",\n",
    "    \"5\": \"customer service\",\n",
    "    \"6\": \"doctor/health care\",\n",
    "    \"7\": \"executive/managerial\",\n",
    "    \"8\": \"farmer\",\n",
    "    \"9\": \"homemaker\",\n",
    "    \"10\": \"K-12 student\",\n",
    "    \"11\": \"lawyer\",\n",
    "    \"12\": \"programmer\",\n",
    "    \"13\": \"retired\",\n",
    "    \"14\": \"sales/marketing\",\n",
    "    \"15\": \"scientist\",\n",
    "    \"16\": \"self-employed\",\n",
    "    \"17\": \"technician/engineer\",\n",
    "    \"18\": \"tradesman/craftsman\",\n",
    "    \"19\": \"unemployed\",\n",
    "    \"20\": \"writer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age='Under 18', gender='F', occupation='K-12 student', userID=1, zipcode='48067'),\n",
       " Row(age='Over 56', gender='M', occupation='self-employed', userID=2, zipcode='70072'),\n",
       " Row(age='25-34', gender='M', occupation='scientist', userID=3, zipcode='55117'),\n",
       " Row(age='45-49', gender='M', occupation='executive/managerial', userID=4, zipcode='02460'),\n",
       " Row(age='25-34', gender='M', occupation='writer', userID=5, zipcode='55455')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the RDD of strings into an RDD of structured Rows.\n",
    "usersRdd1 = usersRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                     .map(lambda t: Row(userID=int(t[0]),\n",
    "                                        gender=t[1],\n",
    "                                        age=agesDict[t[2]],\n",
    "                                        occupation=occupationsDict[t[3]],\n",
    "                                        zipcode=t[4]))\n",
    "usersRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+-------+\n",
      "|age     |gender|occupation          |userID|zipcode|\n",
      "+--------+------+--------------------+------+-------+\n",
      "|Under 18|F     |K-12 student        |1     |48067  |\n",
      "|Over 56 |M     |self-employed       |2     |70072  |\n",
      "|25-34   |M     |scientist           |3     |55117  |\n",
      "|45-49   |M     |executive/managerial|4     |02460  |\n",
      "|25-34   |M     |writer              |5     |55455  |\n",
      "+--------+------+--------------------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a DataFrame from the RDD.\n",
    "usersDf1 = ss.createDataFrame(usersRdd1)\n",
    "usersDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, gender: string, occupation: string, userID: bigint, zipcode: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist it for better performance.\n",
    "# usersDf1.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "usersDf1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first each movie record is composed of 3 fields:\n",
    "\n",
    "- movieID: Movie's unique identification.\n",
    "- title: Movie's title and year (see below).\n",
    "- genres: List of all genres the movie fits to.\n",
    "\n",
    "The `title` field includes the movie's year because there are movies with same name made (or remade) in different years, so the year information would be the only way to distinct them. However, as we have a `movieID` field, this is not really necessary. So we can extract the year from the title and make another field.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each movie is split, the field values are computed, and the result is put into a structured `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(genres=['Animation', \"Children's\", 'Comedy'], movieID=1, title='Toy Story', year=1995),\n",
       " Row(genres=['Adventure', \"Children's\", 'Fantasy'], movieID=2, title='Jumanji', year=1995),\n",
       " Row(genres=['Comedy', 'Romance'], movieID=3, title='Grumpier Old Men', year=1995),\n",
       " Row(genres=['Comedy', 'Drama'], movieID=4, title='Waiting to Exhale', year=1995),\n",
       " Row(genres=['Comedy'], movieID=5, title='Father of the Bride Part II', year=1995)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the RDD of strings into an RDD of structured Rows.\n",
    "moviesRdd1 = moviesRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                       .map(lambda t: Row(movieID=int(t[0]),\n",
    "                                          title=t[1][:-7],\n",
    "                                          year=int(t[1][-5:-1]),\n",
    "                                          genres=t[2].split(\"|\")))\n",
    "moviesRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------+---------------------------+----+\n",
      "|genres                          |movieID|title                      |year|\n",
      "+--------------------------------+-------+---------------------------+----+\n",
      "|[Animation, Children's, Comedy] |1      |Toy Story                  |1995|\n",
      "|[Adventure, Children's, Fantasy]|2      |Jumanji                    |1995|\n",
      "|[Comedy, Romance]               |3      |Grumpier Old Men           |1995|\n",
      "|[Comedy, Drama]                 |4      |Waiting to Exhale          |1995|\n",
      "|[Comedy]                        |5      |Father of the Bride Part II|1995|\n",
      "+--------------------------------+-------+---------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a DataFrame from the RDD.\n",
    "moviesDf1 = ss.createDataFrame(moviesRdd1)\n",
    "moviesDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genres: array<string>, movieID: bigint, title: string, year: bigint]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist it for better performance.\n",
    "# moviesDf1.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "moviesDf1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each rating data is composed of 4 fields:\n",
    "\n",
    "- userID: ID of the user who gave the rating.\n",
    "- movieID: ID of the rated movie.\n",
    "- rating: A numerical value ranging from 1 (min) to 5 (max).\n",
    "- timestamp: An integer number that encodes the date and time the rating was given at.\n",
    "\n",
    "The `timestamp` can be easily converted to a `datetime` object, which is much easier to interpret.\n",
    "\n",
    "Thus, in the following cells the plain textual data for each rating is split, the field values are computed, and the result is put into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieID=1193, rating=5.0, timestamp=datetime.datetime(2000, 12, 31, 20, 12, 40), userID=1),\n",
       " Row(movieID=661, rating=3.0, timestamp=datetime.datetime(2000, 12, 31, 20, 35, 9), userID=1),\n",
       " Row(movieID=914, rating=3.0, timestamp=datetime.datetime(2000, 12, 31, 20, 32, 48), userID=1),\n",
       " Row(movieID=3408, rating=4.0, timestamp=datetime.datetime(2000, 12, 31, 20, 4, 35), userID=1),\n",
       " Row(movieID=2355, rating=5.0, timestamp=datetime.datetime(2001, 1, 6, 21, 38, 11), userID=1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the RDD of strings into an RDD of structured Rows.\n",
    "ratingsRdd1 = ratingsRdd0.map(lambda line: line.split(\"::\")) \\\n",
    "                         .map(lambda t: Row(userID=int(t[0]),\n",
    "                                            movieID=int(t[1]),\n",
    "                                            rating=float(t[2]),\n",
    "                                            timestamp=dt.datetime.fromtimestamp(int(t[3]))))\n",
    "ratingsRdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------------------+------+\n",
      "|movieID|rating|timestamp            |userID|\n",
      "+-------+------+---------------------+------+\n",
      "|1193   |5.0   |2000-12-31 20:12:40.0|1     |\n",
      "|661    |3.0   |2000-12-31 20:35:09.0|1     |\n",
      "|914    |3.0   |2000-12-31 20:32:48.0|1     |\n",
      "|3408   |4.0   |2000-12-31 20:04:35.0|1     |\n",
      "|2355   |5.0   |2001-01-06 21:38:11.0|1     |\n",
      "+-------+------+---------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a DataFrame from the RDD.\n",
    "ratingsDf1 = ss.createDataFrame(ratingsRdd1)\n",
    "ratingsDf1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist it for better performance.\n",
    "# ratingsDf1.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "ratingsDf1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll just do some exploration on the structured datasets in order to better understand all the data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create temporary views that can be accessed by SQL queries.\n",
    "usersDf1.createOrReplaceTempView(\"users\")\n",
    "moviesDf1.createOrReplaceTempView(\"movies\")\n",
    "ratingsDf1.createOrReplaceTempView(\"ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of users.\n",
    "numUsers = usersDf1.count()\n",
    "numUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|gender|frequency|\n",
      "+------+---------+\n",
      "|     M|     4331|\n",
      "|     F|     1709|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the gender distribution.\n",
    "ss.sql(\"\"\"SELECT gender, \n",
    "                 COUNT(gender) as frequency\n",
    "          FROM users\n",
    "          GROUP BY gender\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|     age|frequency|\n",
      "+--------+---------+\n",
      "|   25-34|     2096|\n",
      "|   35-44|     1193|\n",
      "|   18-24|     1103|\n",
      "|   45-49|      550|\n",
      "|   50-55|      496|\n",
      "| Over 56|      380|\n",
      "|Under 18|      222|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the age distribution.\n",
    "ss.sql(\"\"\"SELECT age,\n",
    "                 COUNT(age) as frequency\n",
    "          FROM users\n",
    "          GROUP BY age\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|          occupation|frequency|\n",
      "+--------------------+---------+\n",
      "|college/grad student|      759|\n",
      "|other or unspecified|      711|\n",
      "|executive/managerial|      679|\n",
      "|   academic/educator|      528|\n",
      "| technician/engineer|      502|\n",
      "|          programmer|      388|\n",
      "|     sales/marketing|      302|\n",
      "|              writer|      281|\n",
      "|              artist|      267|\n",
      "|       self-employed|      241|\n",
      "|  doctor/health care|      236|\n",
      "|        K-12 student|      195|\n",
      "|      clerical/admin|      173|\n",
      "|           scientist|      144|\n",
      "|             retired|      142|\n",
      "|              lawyer|      129|\n",
      "|    customer service|      112|\n",
      "|           homemaker|       92|\n",
      "|          unemployed|       72|\n",
      "| tradesman/craftsman|       70|\n",
      "|              farmer|       17|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the occupation distribution.\n",
    "ss.sql(\"\"\"SELECT occupation,\n",
    "                 COUNT(occupation) as frequency\n",
    "          FROM users\n",
    "          GROUP BY occupation\n",
    "          ORDER BY frequency DESC\"\"\").show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+---------+\n",
      "|gender|     age|          occupation|frequency|\n",
      "+------+--------+--------------------+---------+\n",
      "|     M|   18-24|college/grad student|      371|\n",
      "|     M|   25-34|other or unspecified|      206|\n",
      "|     M|   25-34|executive/managerial|      191|\n",
      "|     M|   25-34| technician/engineer|      180|\n",
      "|     M|   35-44|executive/managerial|      177|\n",
      "|     M|   25-34|          programmer|      164|\n",
      "|     F|   18-24|college/grad student|      163|\n",
      "|     M|   25-34|college/grad student|      141|\n",
      "|     M|   35-44| technician/engineer|      116|\n",
      "|     M|Under 18|        K-12 student|      100|\n",
      "|     M|   25-34|     sales/marketing|       97|\n",
      "|     M|   35-44|other or unspecified|       92|\n",
      "|     F|   25-34|other or unspecified|       92|\n",
      "|     M|   25-34|              writer|       89|\n",
      "|     M|   25-34|   academic/educator|       87|\n",
      "|     M|   25-34|              artist|       82|\n",
      "|     M|   35-44|   academic/educator|       77|\n",
      "|     M| Over 56|             retired|       75|\n",
      "|     M|   18-24|other or unspecified|       74|\n",
      "|     M|   35-44|          programmer|       71|\n",
      "+------+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the user groups stratified.\n",
    "ss.sql(\"\"\"SELECT gender,\n",
    "                 age,\n",
    "                 occupation,\n",
    "                 COUNT(*) as frequency\n",
    "          FROM users\n",
    "          GROUP BY gender, age, occupation\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our users belong to the group of male college/grad students aged 18-24 (which is not surprising). The next 3 most populated groups are also composed of men, with various occupations and aged 25-34. Oddly, female users are a minority (why did women watch/rate about 3 times less movies than men? This is probably worthy a deeper investigation...), as well as people at the limits of the age distribution (under 18 and above 56). As one might expect, farmers and tradesman/craftsman are among the least frequent occupations among the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of movies.\n",
    "numMovies = moviesDf1.count()\n",
    "numMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year|frequency|\n",
      "+----+---------+\n",
      "|1996|      345|\n",
      "|1995|      342|\n",
      "|1998|      337|\n",
      "|1997|      315|\n",
      "|1999|      283|\n",
      "|1994|      257|\n",
      "|1993|      165|\n",
      "|2000|      156|\n",
      "|1986|      104|\n",
      "|1992|      102|\n",
      "|1990|       77|\n",
      "|1987|       71|\n",
      "|1988|       69|\n",
      "|1985|       65|\n",
      "|1984|       60|\n",
      "|1989|       60|\n",
      "|1991|       60|\n",
      "|1982|       50|\n",
      "|1981|       43|\n",
      "|1980|       41|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the year distribution.\n",
    "ss.sql(\"\"\"SELECT year,\n",
    "                 COUNT(year) as frequency\n",
    "          FROM movies\n",
    "          GROUP BY year\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|min_year|max_year|avg_year|\n",
      "+--------+--------+--------+\n",
      "|    1919|    2000|  1986.1|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get some year statistics.\n",
    "ss.sql(\"\"\"SELECT MIN(year) as min_year,\n",
    "                 MAX(year) as max_year,\n",
    "                 ROUND(AVG(year), 1) as avg_year\n",
    "          FROM movies\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All movies in the dataset were made between the years of 1919 and 2000. Most of them are from more recent decades, since the mean year is 1986. More precisely, most rated movies are from the 1990s (particularly 1996)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of movies.\n",
    "numRatings = ratingsDf1.count()\n",
    "numRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|rating|frequency|\n",
      "+------+---------+\n",
      "|   4.0|   348971|\n",
      "|   3.0|   261197|\n",
      "|   5.0|   226310|\n",
      "|   2.0|   107557|\n",
      "|   1.0|    56174|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the rating distribution.\n",
    "ss.sql(\"\"\"SELECT rating,\n",
    "                 COUNT(rating) as frequency\n",
    "          FROM ratings\n",
    "          GROUP BY rating\n",
    "          ORDER BY frequency DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+\n",
      "|userID|numRatings|avgRating|\n",
      "+------+----------+---------+\n",
      "|  4169|      2314|      3.6|\n",
      "|  1680|      1850|      3.6|\n",
      "|  4277|      1743|      4.1|\n",
      "|  1941|      1595|      3.1|\n",
      "|  1181|      1521|      2.8|\n",
      "|   889|      1518|      2.8|\n",
      "|  3618|      1344|      3.0|\n",
      "|  2063|      1323|      2.9|\n",
      "|  1150|      1302|      2.6|\n",
      "|  1015|      1286|      3.7|\n",
      "|  5795|      1277|      3.1|\n",
      "|  4344|      1271|      3.3|\n",
      "|  1980|      1260|      3.5|\n",
      "|  2909|      1258|      3.8|\n",
      "|  1449|      1243|      2.8|\n",
      "|  4510|      1240|      2.8|\n",
      "|   424|      1226|      3.7|\n",
      "|  4227|      1222|      2.7|\n",
      "|  5831|      1220|      3.7|\n",
      "|  3391|      1216|      3.7|\n",
      "+------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most active users and their average ratings.\n",
    "ss.sql(\"\"\"SELECT userID,\n",
    "                 COUNT(userID) as numRatings,\n",
    "                 ROUND(AVG(rating), 1) as avgRating\n",
    "          FROM ratings\n",
    "          GROUP BY userID\n",
    "          ORDER BY numRatings DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+----+----------+------------------+\n",
      "|title                                         |year|numRatings|avgRating         |\n",
      "+----------------------------------------------+----+----------+------------------+\n",
      "|American Beauty                               |1999|3428      |4.3173862310385065|\n",
      "|Star Wars: Episode IV - A New Hope            |1977|2991      |4.453694416583082 |\n",
      "|Star Wars: Episode V - The Empire Strikes Back|1980|2990      |4.292976588628763 |\n",
      "|Star Wars: Episode VI - Return of the Jedi    |1983|2883      |4.022892819979188 |\n",
      "|Saving Private Ryan                           |1998|2653      |4.337353938937053 |\n",
      "|Raiders of the Lost Ark                       |1981|2514      |4.477724741447892 |\n",
      "|Silence of the Lambs, The                     |1991|2578      |4.3518231186966645|\n",
      "|Matrix, The                                   |1999|2590      |4.315830115830116 |\n",
      "|Sixth Sense, The                              |1999|2459      |4.406262708418057 |\n",
      "|Terminator 2: Judgment Day                    |1991|2649      |4.058512646281616 |\n",
      "|Fargo                                         |1996|2513      |4.254675686430561 |\n",
      "|Schindler's List                              |1993|2304      |4.510416666666667 |\n",
      "|Braveheart                                    |1995|2443      |4.234957020057307 |\n",
      "|Back to the Future                            |1985|2583      |3.9903213317847466|\n",
      "|Shawshank Redemption, The                     |1994|2227      |4.554557700942973 |\n",
      "|Godfather, The                                |1972|2223      |4.524966261808367 |\n",
      "|Jurassic Park                                 |1993|2672      |3.7638473053892216|\n",
      "|Princess Bride, The                           |1987|2318      |4.3037100949094045|\n",
      "|Shakespeare in Love                           |1998|2369      |4.127479949345715 |\n",
      "|L.A. Confidential                             |1997|2288      |4.219405594405594 |\n",
      "+----------------------------------------------+----+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the overall rank of movies combining both their average rating\n",
    "# and the number of ratings.\n",
    "ss.sql(\"\"\"SELECT movies.title,\n",
    "                 movies.year,\n",
    "                 COUNT(ratings.movieID) as numRatings,\n",
    "                 AVG(ratings.rating) as avgRating\n",
    "          FROM ratings\n",
    "               INNER JOIN movies\n",
    "               ON ratings.movieID = movies.movieID\n",
    "          GROUP BY ratings.movieID,\n",
    "                   movies.title,\n",
    "                   movies.year\n",
    "          ORDER BY (avgRating * numRatings / %s) DESC\"\"\" % numUsers) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 4 stars is the most common rating and 1-2 stars are the least ones, we can say that there aren't many terribly bad movies in the dataset (in our users' opinions). There are users that rated over 1000 movies (and they probably should be rewarded for such contribution), as well as movies that were rated by over 2000 users.\n",
    "\n",
    "American Beauty (1999) is the most rated movie and also the top ranked one when we combine both the average rating and the number of ratings to compute a final score (because being a 5-star movie according to only 1 user means nothing - quantity is important too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preprocessing stage we put all data in good shape for the learning algorithms that come later. This may involve feature encoding, scaling, transforming, splitting, joining, etc.\n",
    "\n",
    "As the goal here is to use collaborative filtering, the only data that needs to be preprocessed is the `ratings` dataset, because only the explicit feedback scores (aka the ratings) are needed to learn the recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should the recommender system do when it finds a new user that never rated anything before (i.e. nothing is known about his/her tastes)? A common approach is just recommending the overall top rated movies. This can be done in a simple manner by shifting each movie's rating relative to its average value (i.e. making ratings have zero mean) and then, in the end, adding such average value to the score predicted for that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---------------------+\n",
      "|movieID|avgRating         |freqRating           |\n",
      "+-------+------------------+---------------------+\n",
      "|29     |4.062034739454094 |0.06672185430463576  |\n",
      "|1806   |2.892857142857143 |0.02781456953642384  |\n",
      "|474    |3.825102880658436 |0.1609271523178808   |\n",
      "|2453   |3.25              |0.02913907284768212  |\n",
      "|2529   |3.712564543889845 |0.1923841059602649   |\n",
      "|2040   |2.9453125         |0.02119205298013245  |\n",
      "|26     |3.53              |0.016556291390728478 |\n",
      "|3506   |3.3652694610778444|0.027649006622516556 |\n",
      "|3091   |4.283687943262412 |0.023344370860927152 |\n",
      "|2250   |3.1451612903225805|0.010264900662251655 |\n",
      "|1677   |2.7567567567567566|0.006125827814569536 |\n",
      "|1950   |4.129310344827586 |0.0576158940397351   |\n",
      "|3764   |2.6408163265306124|0.04056291390728477  |\n",
      "|2927   |4.08080808080808  |0.01639072847682119  |\n",
      "|964    |3.392156862745098 |0.008443708609271523 |\n",
      "|2509   |2.7777777777777777|0.002980132450331126 |\n",
      "|2214   |3.0               |1.6556291390728477E-4|\n",
      "|1840   |3.38125           |0.026490066225165563 |\n",
      "|1277   |3.884297520661157 |0.06009933774834437  |\n",
      "|541    |4.273333333333333 |0.2980132450331126   |\n",
      "+-------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the average rating and the rating frequency by movie.\n",
    "ratingStatsDf = ss.sql(\"\"\"SELECT movieID,\n",
    "                                 AVG(rating) as avgRating,\n",
    "                                 (COUNT(movieID) / %s) as freqRating\n",
    "                          FROM ratings\n",
    "                          GROUP BY movieID\"\"\" % numUsers)\n",
    "ratingStatsDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, avgRating: double, freqRating: double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingStatsDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingStatsDf.createTempView(\"ratingStats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+\n",
      "|movieID|userID|rating|      shiftedRating|\n",
      "+-------+------+------+-------------------+\n",
      "|     26|    18|   4.0| 0.4700000000000002|\n",
      "|     26|    69|   4.0| 0.4700000000000002|\n",
      "|     26|   229|   4.0| 0.4700000000000002|\n",
      "|     26|   342|   4.0| 0.4700000000000002|\n",
      "|     26|   524|   3.0|-0.5299999999999998|\n",
      "|     26|   655|   3.0|-0.5299999999999998|\n",
      "|     26|   748|   5.0| 1.4700000000000002|\n",
      "|     26|   881|   3.0|-0.5299999999999998|\n",
      "|     26|   890|   3.0|-0.5299999999999998|\n",
      "|     26|   918|   4.0| 0.4700000000000002|\n",
      "|     26|   963|   4.0| 0.4700000000000002|\n",
      "|     26|   973|   4.0| 0.4700000000000002|\n",
      "|     26|  1015|   3.0|-0.5299999999999998|\n",
      "|     26|  1069|   3.0|-0.5299999999999998|\n",
      "|     26|  1120|   3.0|-0.5299999999999998|\n",
      "|     26|  1150|   3.0|-0.5299999999999998|\n",
      "|     26|  1182|   2.0|-1.5299999999999998|\n",
      "|     26|  1203|   4.0| 0.4700000000000002|\n",
      "|     26|  1279|   3.0|-0.5299999999999998|\n",
      "|     26|  1314|   1.0|              -2.53|\n",
      "+-------+------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the ratings relative to \n",
    "ratingsDf2 = ss.sql(\"\"\"SELECT ratings.movieID,\n",
    "                              userID,\n",
    "                              rating,\n",
    "                              (rating - avgRating) as shiftedRating\n",
    "                       FROM ratings\n",
    "                            INNER JOIN ratingStats\n",
    "                            ON ratings.movieID = ratingStats.movieID\"\"\")\n",
    "ratingsDf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, userID: bigint, rating: double, shiftedRating: double]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratingsDf2.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "ratingsDf2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, rating: double, timestamp: timestamp, userID: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop stuff that aren't needed anymore.\n",
    "ratingsDf1.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, the collaborative filtering technique only requires us to provide the user IDs, the movie IDs and the rating each user gave to each movie they watched. The *Alternating Least Squares (ALS)* technique is then used to learn weight parameters that best fit the data for each user and can predict the ratings a user would probably give to a movie he/she has never seen before.\n",
    "\n",
    "Parameter tuning (the process of finding the best combination of input parameters for the learning algorithm) was performed using a grid-search with a 3-fold cross-validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Alternating Least Squares (ALS) estimator.\n",
    "als = ALS(userCol=\"userID\",\n",
    "          itemCol=\"movieID\",\n",
    "          ratingCol=\"shiftedRating\",\n",
    "          maxIter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the parameter grid for tuning.\n",
    "paramGrid = ParamGridBuilder().addGrid(als.regParam, [0.01, 0.1, 1]) \\\n",
    "                              .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3-fold cross-validation procedure.\n",
    "alsCV = CrossValidator(estimator=als,\n",
    "                       estimatorParamMaps=paramGrid,\n",
    "                       evaluator=RegressionEvaluator(labelCol=\"shiftedRating\"),\n",
    "                       numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "alsModel = alsCV.fit(ratingsDf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+-----------------+\n",
      "|movieID|userID|rating|      shiftedRating|shiftedPrediction|\n",
      "+-------+------+------+-------------------+-----------------+\n",
      "|    148|    53|   5.0|  2.217391304347826|        1.5828782|\n",
      "|    148|   673|   5.0|  2.217391304347826|        2.4099007|\n",
      "|    148|  4169|   3.0|0.21739130434782616|       0.70518947|\n",
      "|    148|  4227|   2.0|-0.7826086956521738|       -1.3721882|\n",
      "|    148|  5333|   3.0|0.21739130434782616|      -0.48261184|\n",
      "|    148|  3184|   4.0| 1.2173913043478262|        0.8259024|\n",
      "|    148|  4387|   1.0|-1.7826086956521738|       -1.2662555|\n",
      "|    148|  4784|   3.0|0.21739130434782616|        0.9237462|\n",
      "|    148|  2383|   2.0|-0.7826086956521738|      -0.16618633|\n",
      "|    148|  1242|   3.0|0.21739130434782616|       0.17920734|\n",
      "|    148|  3539|   3.0|0.21739130434782616|       -0.1194027|\n",
      "|    148|  1069|   2.0|-0.7826086956521738|      -0.70462483|\n",
      "|    148|  1605|   2.0|-0.7826086956521738|       -0.7226115|\n",
      "|    148|   840|   1.0|-1.7826086956521738|       -0.5433437|\n",
      "|    148|   216|   2.0|-0.7826086956521738|       -0.3896071|\n",
      "|    148|   482|   2.0|-0.7826086956521738|      0.025528744|\n",
      "|    148|   752|   4.0| 1.2173913043478262|        0.2907719|\n",
      "|    148|  1150|   2.0|-0.7826086956521738|      -0.33299315|\n",
      "|    148|  3829|   2.0|-0.7826086956521738|       -1.0219238|\n",
      "|    148|   424|   4.0| 1.2173913043478262|        0.7251413|\n",
      "+-------+------+------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shiftedPredictionsDf = alsModel.transform(ratingsDf2) \\\n",
    "                               .withColumnRenamed(\"prediction\", \"shiftedPrediction\")\n",
    "shiftedPredictionsDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model predicts recommendation scores that are relative to each movies' average ratings. In order to convert them to the true, unshifted scores, some additional operations must be performed. The function below defines such operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, inputsDf, ratingStatsDf):\n",
    "    \"\"\"Makes the final (unshifted) rating predictions according to the given movies and users.\n",
    "    \n",
    "    Inputs:\n",
    "        model          The pretrained predictive model.\n",
    "        inputsDf       A DataFrame containing the user and movie IDs for which the predictions will be made.\n",
    "        ratingStatsDf  A DataFrame containing the rating statistics for each movie.\n",
    "\n",
    "    Outputs:\n",
    "        outputsDf  Same as inputsDf + a new column with the unshifted predictions. \n",
    "    \"\"\"\n",
    "    outputsDf = model.transform(inputsDf) \\\n",
    "                     .withColumnRenamed(\"prediction\", \"shiftedPrediction\") \\\n",
    "                     .fillna(0, \"shiftedPrediction\") \\\n",
    "                     .join(ratingStatsDf, [\"movieID\"]) \\\n",
    "                     .withColumn(\"prediction\", col(\"shiftedPrediction\") + col(\"avgRating\"))\n",
    "\n",
    "    return outputsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+-----------------+-----------------+--------------------+------------------+\n",
      "|movieID|userID|rating|      shiftedRating|shiftedPrediction|        avgRating|          freqRating|        prediction|\n",
      "+-------+------+------+-------------------+-----------------+-----------------+--------------------+------------------+\n",
      "|    148|    53|   5.0|  2.217391304347826|        1.5828782|2.782608695652174|0.003807947019867...| 4.365486927654432|\n",
      "|    148|   673|   5.0|  2.217391304347826|        2.4099007|2.782608695652174|0.003807947019867...| 5.192509360935377|\n",
      "|    148|  4169|   3.0|0.21739130434782616|       0.70518947|2.782608695652174|0.003807947019867...|3.4877981621286143|\n",
      "|    148|  4227|   2.0|-0.7826086956521738|       -1.3721882|2.782608695652174|0.003807947019867...|1.4104204851648081|\n",
      "|    148|  5333|   3.0|0.21739130434782616|      -0.48261184|2.782608695652174|0.003807947019867...|2.2999968606492747|\n",
      "|    148|  3184|   4.0| 1.2173913043478262|        0.8259024|2.782608695652174|0.003807947019867...|3.6085110980531443|\n",
      "|    148|  4387|   1.0|-1.7826086956521738|       -1.2662555|2.782608695652174|0.003807947019867...|1.5163531977197398|\n",
      "|    148|  4784|   3.0|0.21739130434782616|        0.9237462|2.782608695652174|0.003807947019867...|3.7063549238702524|\n",
      "|    148|  2383|   2.0|-0.7826086956521738|      -0.16618633|2.782608695652174|0.003807947019867...| 2.616422362949537|\n",
      "|    148|  1242|   3.0|0.21739130434782616|       0.17920734|2.782608695652174|0.003807947019867...|2.9618160355350245|\n",
      "|    148|  3539|   3.0|0.21739130434782616|       -0.1194027|2.782608695652174|0.003807947019867...| 2.663205996479677|\n",
      "|    148|  1069|   2.0|-0.7826086956521738|      -0.70462483|2.782608695652174|0.003807947019867...|2.0779838639756907|\n",
      "|    148|  1605|   2.0|-0.7826086956521738|       -0.7226115|2.782608695652174|0.003807947019867...|   2.0599972087404|\n",
      "|    148|   840|   1.0|-1.7826086956521738|       -0.5433437|2.782608695652174|0.003807947019867...| 2.239264972831892|\n",
      "|    148|   216|   2.0|-0.7826086956521738|       -0.3896071|2.782608695652174|0.003807947019867...|2.3930015939733256|\n",
      "|    148|   482|   2.0|-0.7826086956521738|      0.025528744|2.782608695652174|0.003807947019867...|2.8081374395152796|\n",
      "|    148|   752|   4.0| 1.2173913043478262|        0.2907719|2.782608695652174|0.003807947019867...|3.0733805972596873|\n",
      "|    148|  1150|   2.0|-0.7826086956521738|      -0.33299315|2.782608695652174|0.003807947019867...|2.4496155458947886|\n",
      "|    148|  3829|   2.0|-0.7826086956521738|       -1.0219238|2.782608695652174|0.003807947019867...|1.7606849152108897|\n",
      "|    148|   424|   4.0| 1.2173913043478262|        0.7251413|2.782608695652174|0.003807947019867...|3.5077499825021494|\n",
      "+-------+------+------+-------------------+-----------------+-----------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDf = predict(alsModel, ratingsDf2, ratingStatsDf)\n",
    "predictionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieID: bigint, userID: bigint, rating: double, shiftedRating: double, shiftedPrediction: float, avgRating: double, freqRating: double, prediction: double]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictionsDf.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "predictionsDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the recommender model predicts real numbers, it can be evaluated using the *Root Mean Squared Error* (RMSE) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate using the root mean squared error (RMSE).\n",
    "rmse = RegressionEvaluator(labelCol=\"rating\",\n",
    "                           predictionCol=\"prediction\",\n",
    "                           metricName=\"rmse\").evaluate(predictionsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 0.775064\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The reason I trained and tested the model on the same dataset (instead of randomly splitting it into two disjoint datasets, one for training and the other for test) is [this bug](https://issues.apache.org/jira/browse/SPARK-14489). Apparently the problem was fixed in Spark 2.2.0 with the addition of a new input parameter for `ALS`, but I'm currently using Spark 2.1.0 (latest stable version when I wrote this), so it is not available yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the recommender model is finally ready to be used! Predicting the ratings that specific users would give to specific movies is simply a matter of filling a `DataFrame` with the desired `movieID`s and `userID`s and sending it as input to the `predict()` function. The result will be another `DataFrame` containing an additional column with the predictions (among others).\n",
    "\n",
    "Notice that, when the input data contains some new `userID` unknown to the model, the shifted predicted rating for the requested movie is 0. Hence, the final prediction is simply the overall average rating for that movie. This is a reasonable strategy: if we know nothing about some user's tastes, just recommend them popular movies that most people liked.\n",
    "\n",
    "When the `movieID` is unknown by the model, such movie is simply ignored: no prediction is made for it. This is also a reasonable strategy, because it may not be a good idea to recommend a movie we know nothing about. Better wait until it receives some ratings first. Were we building a hybrid recommender system (e.g. a model that combines collaborative filtering with content-based recommendation), a different strartegy could be employed for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieID|userID|\n",
      "+-------+------+\n",
      "|     26|   100|\n",
      "|     26|   200|\n",
      "|     29|   100|\n",
      "|     29|   200|\n",
      "|    100|     0|\n",
      "|    200|     0|\n",
      "|      0|   100|\n",
      "|      0|   200|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define some test data.\n",
    "testDf = ss.createDataFrame([(26, 100),\n",
    "                             (26, 200),\n",
    "                             (29, 100),\n",
    "                             (29, 200),\n",
    "                             (100, 0),   # unknown user\n",
    "                             (200, 0),   # unknown user\n",
    "                             (0, 100),   # unknown movie\n",
    "                             (0, 200)],  # unknown movie\n",
    "                            [\"movieID\", \"userID\"])\n",
    "testDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+------------------+--------------------+------------------+\n",
      "|movieID|userID|shiftedPrediction|avgRating         |freqRating          |prediction        |\n",
      "+-------+------+-----------------+------------------+--------------------+------------------+\n",
      "|26     |100   |-0.78005         |3.53              |0.016556291390728478|2.7499500203132627|\n",
      "|26     |200   |0.6017402        |3.53              |0.016556291390728478|4.131740181446075 |\n",
      "|100    |0     |0.0              |3.0625            |0.02119205298013245 |3.0625            |\n",
      "|29     |100   |-0.6050494       |4.062034739454094 |0.06672185430463576 |3.4569853677347337|\n",
      "|29     |200   |0.75856614       |4.062034739454094 |0.06672185430463576 |4.820600880582634 |\n",
      "|200    |0     |0.0              |2.4166666666666665|0.001986754966887417|2.4166666666666665|\n",
      "+-------+------+-----------------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for them. Notice that:\n",
    "#   - When the user is unknown, the predicted rating is just the movie's overall average rating.\n",
    "#   - When the movie is unknown, no prediction is made for it.\n",
    "predict(alsModel, testDf, ratingStatsDf).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And if we want to recommend a list of `N` movies that a specific user is most likely to enjoy, the function below can be used. It basically builds a `DataFrame` with all the movies the user never watched and predicts a rating (score) for each of these movies, using the pretrained model. The results are sorted in order to put the `N` highest predicted values as the top recommendations for such user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend(model, userID, moviesDf, ratingsDf, ratingStatsDf, n=10):\n",
    "    \"\"\"Computes movie recommendations for a single user.\n",
    "    \n",
    "    Inputs:\n",
    "        model          The pretrained predictive model.\n",
    "        moviesDf       A DataFrame containing all the movies.\n",
    "        ratingsDf      A DataFrame containing all the ratings.\n",
    "        ratingStatsDf  A DataFrame containing the rating statistics for each movie.\n",
    "        n              The maximum number of recommendations.\n",
    "\n",
    "    Outputs:\n",
    "        outputsDf  Same as inputsDf + a new column with the unshifted predictions. \n",
    "    \"\"\"\n",
    "    ratedDf = ratingsDf.where(col(\"userID\") == userID) \\\n",
    "                       .select(\"movieID\")\n",
    "    unratedDf = moviesDf.join(ratedDf, moviesDf[\"movieID\"] == ratedDf[\"movieID\"], \"left_outer\") \\\n",
    "                        .where(ratedDf[\"movieID\"].isNull()) \\\n",
    "                        .select(moviesDf[\"movieID\"])\n",
    "\n",
    "    inputsDf = unratedDf.withColumn(\"userID\", lit(userID))\n",
    "    outputsDf = predict(model, inputsDf, ratingStatsDf) \\\n",
    "                    .orderBy(col(\"prediction\"), ascending=False) \\\n",
    "                    .limit(n) \\\n",
    "                    .select(\"movieID\", \"prediction\") \\\n",
    "                    .join(moviesDf, \"movieID\") \\\n",
    "                    .select(\"movieID\", \"title\", \"year\", \"prediction\")\n",
    "\n",
    "    return outputsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------+----+------------------+\n",
      "|movieID|title                                        |year|prediction        |\n",
      "+-------+---------------------------------------------+----+------------------+\n",
      "|2800   |Little Nemo: Adventures in Slumberland       |1992|7.503374143080277 |\n",
      "|3847   |Ilsa, She Wolf of the SS                     |1974|6.817411861419678 |\n",
      "|2342   |Hard Core Logo                               |1996|6.614123799584128 |\n",
      "|1450   |Prisoner of the Mountains (Kavkazsky Plennik)|1996|6.53896393094744  |\n",
      "|219    |Cure, The                                    |1995|6.406280214136297 |\n",
      "|37     |Across the Sea of Time                       |1995|6.27704644203186  |\n",
      "|3817   |Other Side of Sunday, The (Sndagsengler)    |1996|6.0432658195495605|\n",
      "|1664   |Nnette et Boni                              |1996|5.965112519264221 |\n",
      "|2721   |Trick                                        |1999|5.862164483350866 |\n",
      "|326    |To Live (Huozhe)                             |1994|5.80342119248187  |\n",
      "+-------+---------------------------------------------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommend(alsModel, 1000, moviesDf1, ratingsDf2, ratingStatsDf).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
